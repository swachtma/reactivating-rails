# Chapter 2: React, Rails, and Docker (Oh my).

In this chapter, we set up the client and server-side frameworks for our application.  Using Docker, we can quickly create an environment for development that allows us to move quickly into developing our application.

## Do it with Docker

If you plan to follow along with code examples in this book, I highly recommend you do so using Docker. 

Docker simplifies development by ensuring all the dependencies that make up our application ship alongside our code in simple, disposable containers.  A Docker container is a Linux process which mimics the behavior of a virtual machine.  Each container comes with set up and teardown instructions that instantiate an environment for us.  If two developers compose an application from a single Docker configuration, (Dockerfile) they end with an identical environment, regardless of each developer's local system.

This composability allows development teams to end dependency battles by ensuring everyone is developing in an identical environment.

I hope that Docker can do the same for us; ensuring code I write behaves like the code you do when you follow along with our examples.  I have packaged this book with Docker containers that provide you with Ruby, NodeJS, and Postgres DB installations.  This Docker setup also ensures you are running the correct version of each package, and helps you bootstrap a starter application.

## Installing Docker

To get started, you'll need to install Docker on your local machine.  Rather than duplicating existing documentation, I am going to point you to Docker's installation guides.  You need to install Docker's **Community Edition (Docker CE)**, rejoin me here after you finish the installation.

**Important!** To run the code example in this book you need to allow Docker access to your local file system.  As you follow install instructions below, be sure to grant file system access to the drive/directory where your project resides.
 
### Docker for Windows 10 & Mac

If you run 64-bit Windows 10 Enterprise or Professional edition, or Mac OSX, you'll find a single installation package linked below that gives you access to all the Docker tools you need.

[Installing Docker for Windows](https://docs.docker.com/docker-for-windows/install/)
[Installing Docker for Mac](https://docs.docker.com/docker-for-mac/install/)

### Docker for Windows 8.1 && 7 (Legacy)

If you run an earlier 64-bit version of Windows, you can still use Docker; however, you'll need to follow the legacy setup instructions for Docker Toolkit

[Install Docker Toolkit for Windows 8.1 and below](https://docs.docker.com/toolbox/toolbox_install_windows/#how-to-uninstall-toolbox)


### Docker for Linux

Installing Docker on Linux can be a bit more complicated due to the various Linux distributions in the wild.  Luckily, the fine folks at get.docker.com have you covered with an installation script that handles the heavy lifting.  Following the instructions linked below to execute an install script that guides you through an installation appropriate for your Linux distribution.

[Installing Docker for Linux](https://get.docker.com/)

## Getting Started 

To begin our work together, you'll want to clone a copy of the GitHub repository for this book.  I have paired each chapter of this book with a branch in the repository.  As you read, you can build upon each chapter locally from beginning to end. Alternatively, I provide a branch with starter code for each chapter if you want to jump between sections that interest you.

```bash
# Copy and paste the following commands to check out the starter commit
git clone https://github.com/swachtma/reactivating-rails-app.git && \
cd reactivating-rails-app && \
git checkout project-starter
```

## Setting up with Docker

Before we look at our application, let's review a (very) abbreviated summary of Docker.

Docker uses isolated runtimes called containers to create environments that can be easily instantiated and destroyed.  Typically, each container is designed to run a single area of concern for our application.  For example, our web server typically resides in a separate container than our database.  This structure allows us to quickly scale our application horizontally by duplicating a container across distributed hardware.  If our web server becomes overloaded, we can add more instances on new hardware and manage the whole cluster with a load balancer.  Since our database would typically be in an independent container, we don't need to scale that hardware until the needs of our application demand it.

 A well written Docker container should be an immutable unit; two developers, executing the same container, on two different local environments, should get the same resulting container.  Alternatively, in a production environment, a distributed system of containers (nodes), can use the same set of instruction (called a Dockerfile or image), to replicate a portion of the system across a distributed network of hardware and ensure each instance is a mirror of its peers.

Containers spawn from images, which are in turn built from instructions called Dockerfiles.  A Dockerfile is a series of repeatable instructions that detail how container set up, what software is required, and what should happen after the container initializes.

Our application utilizes three such containers.

One container manages Ruby and Rails, utilizing Puma to run a development server for an API bound to port 3000.

Another container runs a NodeJS installation, utilizing Facebook's Create React App to run a development web server for our client application on port 80.

Finally, a third container provides a Postgres database to store our application data.

### Doker Compose 

To make use of these containers, we need to tell Docker to follow the build instructions in each of our Dockerfiles.  These files are in a hidden `.docker/` directory in the project you cloned.

Managing all these containers might seem overwhelming at first glance.  Luckily, Docker provides another tool for the task; Docker Compose.

Docker Compose provides an application level set of instructions that to define how all our various containers should interact, how networking should happen between them, and how our local file system should map to the application content inside our running containers.  All you have to do is tell Docker Compose to go to work.

Execute the following command in your project's root directory.

```bash
# Execute the following in your project root
docker-compose up --build
```

Docker Compose starts each of our three containers on your behalf and sets about the work of installing dependencies for each.  The first time you run `docker-compose up` we pass it the `--build` flag.  This flag tells Docker that it first needs to create images for each container; think of these images as setting up the necessary machines for our application.

On future executions, you can drop the `--build` flag, and Docker uses a cached copy of each image to recreate the containers it needs without repeating the setup and installation steps.  You won't need to build again unless changes occur in our underlying application environment.

### Dependencies in NPM and Bundler

You might be a bit dismayed the first time you run `docker-compose up`, by the amount of time it takes to execute this command and boot your services.  Don't be.  The first execution of our containers requires NPM and bundler (package managers for Node and Rails) to check, and subsequently install all of their dependencies.  

I have configured Docker to save these dependencies in a dedicated local space that Docker can reuse across containers, and over multiple executions.  These spaces are called Volumes.  On subsequent launches, Docker can bind this volume to your containers before checking the status of dependencies, and skip the installation process if your dependencies are unchanged.  Starting our application in the future can, therefore, happen dramatically faster

### Checking your Server(s)

Once Docker Compose has finished its work, it starts development servers for Rails and React running on ports 3000 and 80 respectively.  Open a browser to visit `localhost`, and you should see the React welcome page.

![CRA Starter App Homepage](/images/2/CRAHomepage.png)

Now point your browser to `localhost:3000` and you should see a similar welcome message from your Rails server.

![Rails Starter App Homepage](/images/2/RailsHomepage.png)

Docker Compose compiles output for each container into a single terminal report.  As requests come into your application, you should see each container reporting the activity in your console.  I've assigned each container a name to detail its function; client, api, and pgdb (Postgres)

![Docker Compose Output](/images/2/DockerComposeOutput.png)

### Understanding the Local File System

When you ran Docker Compose's `up` command, you probably noticed that it created several new local directories for you; an `api/` directory, and a `client/` directory.  I've configured Docker Compose on your behalf to check if you have an existing local project when Compose starts your containers.  If no local project exists, Docker instructs your API and client containers to run setup commands to create new application starters in these directories.

The `api/` directory, is the home of your Rails project, and it is created using the rails generator command; `rails new application_name --api -T --database=postgresql --skip-bundle --skip-git`

The `client/` directory is home to your React application, and is created using Facebook's Create React App; `npx create-react-app application_name`

There's a bit more Docker magic at work here.  Open the file `/client/src/App.js` and replace its contents with the example below.

```javascript(/client/src/App.js)
import React, { Component } from 'react';
import logo from './logo.svg';
import './App.css';

class App extends Component {
  render() {
    return (
      <div className="App">
        <header className="App-header">
          <img src={logo} className="App-logo" alt="logo" />
          <h1 className="App-title">Welcome to React</h1>
        </header>
        <p className="App-intro">
          Hello hot reloading!
        </p>
      </div>
    );
  }
}

export default App;
```

Point your browser back to `localhost`, and prepare to be suitably amazed.

You've probably seen hot reloading before, no big deal.  Consider for a moment though that Docker is running a Linux process on your machine that for most intents is an isolated virtual machine.  So when you make a change to your local file system, you might not assume that this virtual machine would pick up on the fact that changes have occurred.

However, using Docker Compose, I have mapped the `client/` and `api/` directories into each container to overwrite a local folder **within** each container.  That means when you write changes on your local machine Docker ensures that the changes make their way into each container automatically. From there the hot-reloading provided by Rails and Create React App instantly notice our updates and rebuild our applications.

The result is that your local directories give you direct editing ability to the applications running in each container.

Awesome.

### Docker Networking

There's one last piece of Docker magic I have to cover before we move on, networking.

Our containers are now available on ports 80 and 3000 because we have used Docker Compose to map internal ports of our containers to ports on our local machine.  For now, that abstraction is all you need to know. However, it's worth a note that Docker maintains it's own internal private networking interface that containers use to communicate.  On this private network, containers can refer to each other by name, much as you would use a hostname/IP address to route requests on the web.

You can see an example of this in your `database.yml` file's default setting where we refer to our database's host by its container name `pgdb`.

```yml(/api/config/database.yml)
default: &default
  adapter: postgresql
  encoding: unicode
+   host: pgdb
  username: postgres
  password: secretword
  pool: <%= ENV.fetch("RAILS_MAX_THREADS") { 5 } %>
  timeout: 5000
```

Also in our `package.json` file,  we set up a proxy to direct any requests our client can't process onto our Rails application server.

```json(/client/package.json)
{
  "name": "rr_client",
  "version": "0.1.0",
  "private": true,
+   "proxy": "http://api:3000",
  "dependencies": {
    "react": "^16.4.2",
    "react-dom": "^16.4.2",
    "react-scripts": "1.1.4"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test --env=jsdom",
    "eject": "react-scripts eject"
  }
}
```

I've handled this setup for you as part of my Docker Compose setup in the project starter.  It's worth pointing this out to you so that you understand where these settings live should you wish to alter them in the future.

Our package.json file's proxy setting is particularly important, as this allows us to avoid cross-origin request blocking between our client and API server when we begin making requests between the two.  Create React App provides us this proxy ability out of the box, allowing us to declare a proxy path for requests that it cannot handle directly.  We're using Docker's networking layer to compound on this convenience by letting docker manage where that container lies on its network and merely referring to the container by its assigned name when we need to direct traffic that way.

If that's a little greek to you at the moment, don't worry, it should become clear as we work with Docker.

### Stopping the Server(s)

When you finish with your containers, you can execute `docker-compose down` to teardown and stop your development servers.  You should need to do this only rarely, as hot-reloading on the client and API side of our application incorporate local changes to our application code without needing to restart our server.

However, keep this command in mind in case you run into a need to stop your applications entirely.

## Summary

That brings us to the end of Chapter 2.  Using Docker We have set up our client and API servers, and carved out space for both to operate.

In the next chapter we begin our first iteration of actual application development, and bootstrap a **very** simple version of our reader.  We set up the first simple endpoint on our API, and update our client to quickly bootstrap a minimum viable(?) product for our reader.
