# Chapter 11: Token-Based Authentication

We have reached a point where our application could benefit from some persistent state.  I want to implement features that automatically jump readers to their last read position when coming to our application on return visits.  To do that, we need persistent storage extending beyond a single session or device.  It is time to introduce user authentication.

## Getting Started 

If you're starting here or jumping between chapters, I recommend executing the code below to clone the project and check out the branch for this chapter.

``` bash
# Copy and paste the following commands to check out the starter commit
git clone https://github.com/swachtma/reactivating-rails-app.git && \
cd reactivating-rails-app && \
git checkout ch11-starter
```

## The Compounding Complexities of Authentication

I confess, I rather loathe designing authentication for my applications.  Authentication systems tend to be involved undertakings, and extremely prone to scope creep.

Assume we're building the simplest possible authentication system.  Right out of the gate, we need a model for users, and all its usual CRUD actions; registration pages, a login page, a user profile page, and probably some admin pages.  

Don't forget users are sure to forget their passwords, so we need a password reset page.  That requires some form of secondary verification of the user's identity.  So now my application needs to send emails or text messages; I guess I'll be configuring a mailserver now.  Oh, and we need views for our password recovery process; one page to request a reset, and another to set a new password!

Nevermind the fact that logging in doesn't **DO** anything valuable for our users.  Users don't benefit from authentication until we build something on top of it.  The entire login process itself is just boilerplate.  Something to get out of the way before we can move on to better things.

## Planning our Iteration

Trying to avoid as many possible headaches as we can, I have settled on the use of a third party authentication provider.  Using OAuth; we can let someone else can handle registration, account recovery, and account updates; to say nothing of information security.

That allows us to focus as tightly as possible on the one feature we need for our application, identity verification.  All while giving our users a better experience as well.

Although I try to give an introduction, if you haven't worked with OAuth before, it may be helpful to familiarize yourself with the topic.  [Digital Ocean's excellent article on OAuth2](https://www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2) is a helpful summary of the basics.

We are using an Authorization Code authentication pattern for our application.  This pattern requires a server-side application layer, and would not be appropriate for purely client-side applications because it relies on the use of secret keys.

Here is a simple process flow for this OAuth pattern:
1. A user comes to our site and signs-in.
2. Our application redirects to a 3rd party authenticator.
3. The authenticator verifies the user's identity (login).
4. The user is asked to approve our application's access level.
5. After approval, users redirect back to our application with an authentication code.
6. Our server validates this code using a secret key (provided previously by the authenticator).
7. Our application responds with the code, and a client ID identifying our application
8. The authenticator validates our request, responding with an access token dictating our permissions
9. Our server uses this token to query the authenticator for any desired information about the user.
10. We create a user record in our database or fetch an existing user.
11. Our server creates an internal token representing that user and sends it to the client.
12. Our client uses this token to authenticate future actions in our application.

That list of steps might seem more complicated than designing our own complete authentication system.  However, what's not on the list makes a big difference.  If users need to update accounts, recover passwords, or register, they do so with the authenticator.

There is no shortage of OAuth2 providers.  The big names are Google and Facebook, but given our target audience, I am choosing to use GitHub.  

Many applications support several providers, and perhaps also roll their own auth systems as an alternative.  My thoughts on roll-your-own systems are clear at this point.  However, using multiple OAuth providers is also problematic.  If I used GitHub authentication last visit, and Google today, suddenly I have two accounts on the service.  Designers try mitigating this problem by having users link several accounts during signup, or merging overlapping records after several authentication services have created multiple accounts for a user.

I prefer to avoid the whole mess.  I am willing to wager most users in my target audience have Github accounts.  If not, they can decide whether they would like to create one to access our service's authenticated features.

## OAuth Provider Registration

Before we begin, we need to register our application with GitHub.  

You need to register for [Github's developer program](https://github.com/developer/register).

Then, inside your account settings, you have the option to [manage developer settings](https://github.com/settings/developers).

When you make it this far, click the link to register a new OAuth application.

![Create a New OAuth Application](/images/11/RegisterOAuth.png)

The most important parts of this are your homepage and a callback URL.  The callback URL is where GitHub directs users after successfully signing in and approving your application's access to their data.  This URL is where our application regains control and finishes the authentication handshake.  Since this is an API route, I am setting my callback URL as `/api/github` so it is consistent with our existing routes.

![Configure New OAuth Application](/images/11/RegisterOAuth2.png)

Now we have what we need to begin configuring our application.

## Managing Sensitive Keys

Before continuing, we need a way to manage secure keys.  Our application security relies on the secret keys provided by GitHub remaining a secret.  These values must never be committed to our project repositories, and that means keeping these keys out of our source code.  

Many applications would use environment variables for this task. However, environment variables are less secure than often credited.  It's hard to control who has access to environment variables, and some applications might grab and print your entire environment when logging activity.  Using environment variables certainly beats writing secure values into your source code, but Docker offers us a better alternative.

### Docker Secrets

Docker secrets allow us to send secure values into each of our Docker containers; distributing these sensitive values only to services that specifically need access.  For example, we only require our GitHub API secret within API container; our client should never have access because client-side use exposes the value and compromise our security.

If we can prevent our client container receiving secrets in the first place, we reduce the risk of them unwittingly using them insecurely.

Docker Secrets also have the advantage of being encrypted when at rest (on our disk), and when in transit (when sending secrets into each container instance).

To setup Docker Secrets, we're going to create a new folder.  You'll be placing this new folder inside a `/.docker` hidden directory I created to store Docker's configuration for this project.  Inside, create another hidden folder, so you have the path `/.docker/.secrets`.

Immediately add this new directory to the `.gitignore` file in your project's root.  Secrets won't save you if you commit them to your repositories.

```(/.gitignore)
- # Existing ignore rules (do not remove)
- /.c9
- /.cache
- /.gem
- /.gnupg
- /.local
- /.nano
- /.node-gyp
- /.qws
- /.ssh
- /.npm
- 
- #ignore chapter files
- /api/lib/reactivating-rails
- # Ignore all logfiles and tempfiles.
- /api/log/*
- /api/tmp/*
- /api/!/log/.keep
- /api/!/tmp/.keep
- /api/.byebug_history
- # Ignore encrypted secrets key file.
- /api/config/secrets.yml.key
- /api/public/images/*
- 
- .bash_history
- .bashrc
- .cloud-locale-test.skip
- .profile
- .pry_history
- .viminfo
- .wget-hsts
- 
- # dependencies
- /client/node_modules
- 
- # testing
- /client/coverage
- 
- # production
- /client/build
- 
- # Jest cache
- client/jest_0/
- 
- # misc
- /client/.DS_Store
- /client/.env.local
- /client/.env.development.local
- /client/.env.test.local
- /client/.env.production.local
- 
- /client/npm-debug.log*
- /client/yarn-debug.log*
- /client/yarn-error.log*
- #

+ # Docker Secrets
+ /.docker/.secrets/*
```

Next, create two new files; `/.docker/.secret/github_client_secret.txt` and `/.docker/.secret/jwt_secret.txt`.  Populate the new `github_client_secret.txt`  file with your Github Secret.  (Github provided this value when you registered your OAuth application.)

In the interest of making all our docker changes at once, we have also created a second file; `/.docker/.secret/jwt_secret.txt`.  Inside this file, create a **random** string, at least 16 characters long, and ideally a mix of alpha, numeric, and symbol characters.  We'll discuss the use of this value later this chapter.

Now we can map our secrets into our API container, making them available when we start our services with Docker Compose.  To do so, we need to edit our config file, `docker-compose.yml`.

I realize we haven't covered this configuration file previously.  By design, I have tried to make our use of Docker as unobtrusive as possible.  I have tried to demonstrate what development can look like on Docker without attempting to teach you skills you'd need as an administrator.  However, The changes below should be relatively transparent.

``` yaml(docker-compose.yml)
version: "3.7"

services:
  api:
    build: 
      context: .
      dockerfile: ./.docker/ApiDockerfile
    container_name: api
    ports: 
      - 3000:3000
    volumes:
    - ./api:/root/api
    - gems:/usr/local/bundle
    depends_on:
      - pgdb
    command: ["rails","server"]
+     environment:
+       - CLIENT_URL=http://localhost
+       - GITHUB_CLIENT_ID=<GitHub client ID Here>
+     secrets:
+       - github_client_secret
+       - jwt_secret
  client:
    build:
      context: .
      dockerfile: ./.docker/ClientDockerfile
    container_name: client
    ports:
      - 80:3000
      - 35729:35729
    volumes:
      - ./client:/root/client
    command: ["yarn","start"]
  pgdb:
    image: postgres:10-alpine
    container_name: pgdb
    restart: always
    environment:
      POSTGRES_PASSWORD: secretword
    volumes:
      - pgdata:/var/lib/postgresql/data
volumes:
  gems:
  node_modules:
  pgdata:
+ secrets:
+   github_client_secret:
+     file: ./.docker/.secrets/github_client_secret.txt
+   jwt_secret:
+     file: ./.docker/.secrets/jwt_secret.txt
```

The Docker Compose YAML file specifies the details of each container/service we're using in our application.  In our case, we have specified three containers; an API running Ruby and Rails, a client running Node and React, and a Postgres database.  This YAML file details what software runs in each container, what to do on startup, where to store files, where each service lives on our network, and a host of other options.  

We won't be messing with any of those things.

At the bottom of our file, we are declaring a new key `secrets`, under which we define two new secret values `jwt_secret`, and `github_client_secret`.  Each of these secrets is told to pull its values from a local file path (written relative to the location of our `docker-compose.yml` file).  This block creates our secrets inside Docker.

The changes near the top of the file, under the API's `secrets` key, maps our secrets to our API container.  We grant the API access to both named secrets.

Now, when we run `docker-compose up`, Docker defines our two secrets and passes them as encrypted data into **only** our API container.  Each secret arrives as data we can access as part of the containers file system.  (Secrets live in container memory for security reasons, but we can access them as if they were files on disk.)

We have also added an `environment` key to our API container definition.  This key is used to define two new environment variables within our container; the URL of our client, and the client ID issued for our application by GitHub.  Since these values can be publicly exposed, we're passing them as environment variables.  Be sure to replace this value with your own GitHub client ID if you are following along.

Now, let's check our work.  First, stop any containers you might have running using `CTRL + C` to stop Docker Compose.  Then execute `docker-compose down` to teardown any current containers.  Next, start just your API container using `docker-compose run rails console` to boot your API container as an interactive Rails console.

If all went according to plan, our API should have "files" we can read our secret values from located at `/run/secrets/<secret_name>`.  In your Rails console run `File.read("/run/secrets/jwt_secret")`, and you should see it print the random value you created for your secret.

![Fetching a secret value using Ruby's File.read("/run/secrets/jwt_secret") inside the API container.](/images/11/JWTSecretExample.png)

Check your other secret value as well before moving forward, ensuring its available inside your API container.

### Secrets and Docker Compose

It's important I note that how we defined our secrets here is not a production-ready example.  That's due in large part because **Docker Compose is not a production-grade tool**.  Compose is designed to make life easier when running Docker services locally for development.  Defining our secrets in .txt files and mapping them with Compose isn't how we approach secrets in production.

For development though, this creates our secrets easily and does so mirroring the developer experience of a production implementation.  This approach allows us to build our application locally using the same strategies to access secret data in dev that we would in a production release.

With that said, let's move forward.

## Authentication Step by Step

We're now ready to begin building our authentication system.  This iteration is involved, but we can break our work into a few smaller phases.

### Steps 1 - 4: Logging in from our UI

Looking at our list of authentication steps above, we first need to create a  UI control for user authentication.

Open your menu bar component, and make the following changes.

``` javascript(/client/src/components/menu_bar.js)
import React, { Component } from 'react';
+ import { Container, Image, Menu, Icon } from 'semantic-ui-react';
  
import rrLogo from '../assets/images/reactivating-rails.png';
import { ConnectedChapterMenuItems } from '../containers/chapter_provider';

- const fixedMenuStyle = {
-   backgroundColor: '#fff',
-   border: '1px solid #ddd',
-   boxShadow: '0px 3px 5px rgba(0, 0, 0, 0.2)',
-   paddingTop: "8px",
-   paddingBottom: "8px"
- };

class MenuBar extends Component {
  render() {
    return (
        <Menu borderless stackable fixed="top" style={ fixedMenuStyle }>
          <Container>
            <Menu.Item><Image width='200' src={rrLogo} /></Menu.Item>

            <Menu.Menu position='right'>
              <ConnectedChapterMenuItems />
+               <Menu.Item href="https://github.com/login/oauth/authorize?client_id=<YOU CLIENT ID>" name='Sign in with GitHub'>
+                 <Icon name='github' size="big" />
+               </Menu.Item>
            </Menu.Menu>
          </Container>
        </Menu>
    );
  }
}

export default MenuBar;
```

Since GitHub provides the login UI, all we own is a link to take users off-site; we're using a simple GitHub Icon.  We're passing a URL parameter containing our client ID (you need to update this with your unique client ID if you are following along).

Render this update, and click the new link.  You should navigate to a login page on GitHub.

We are not requesting any additional permissions/scopes in our authorization link, so this request only gains us access to the user's public profile.  Luckily, that is all we need.

![Authorize Apllication Page](/images/11/AuthorizeApplication.png)

If you complete the login; GitHub attempts to redirect you to the URL you defined in your application setup.  In my case, that brings me to `http://localhost/api/github`.

### Step 5: Beginning the Authentication Handshake

Now we need to update our API to respond when Github redirects users our way.  That means creating a new controller and route.  Generate those now with the following command: `docker-compose exec api bin/rails generate controller api/authentication github`

Most of this generated content works fine, but we should adjust the route a bit.

``` ruby(/api/config/routes.rb)
Rails.application.routes.draw do
  namespace :api do
+     get 'github/', to: "authentication#github"
    get 'nodes/', to: "nodes#index"
    get 'chapters/', to: "chapters#index"
  end
end
```

With our route in place, let's turn our attention to setting up our controller action.

### Steps 6 - 8 verifying the Github Credentials

We are going to use a gem `github_api` to simplify our interactions with Github's OAuth service.  Let's install the gem using `bundle add` to update our Gemfile, and install the new dependency.

Run the following command in your project root: `docker-compose exec api bundle add github_api --version 0.18.2`

After installing the gem, we are ready to write our new controller action.

Once logged in at GitHub, users redirect to our authentication#github controller action.  That redirect to our API also contains a single URL parameter; `code`.  We use this `code` and our secret key to validate the request, and receive an access token from the GitHub API.  Make the following changes to your controller.

``` ruby(/api/app/controllers/api/authentication_controller.rb)
class Api::AuthenticationController < ApplicationController
  GITHUB_CLIENT_SECRET = File.read("/run/secrets/github_client_secret")
  def github
    code = params[:code]
    github = Github.new client_id: ENV["GITHUB_CLIENT_ID"], client_secret: GITHUB_CLIENT_SECRET
    token = github.get_token(code).token
    
    github_users = Github::Client::Users.new oauth_token: token
    user = User.create_or_fetch(github_users.get)
  end
end
```

This controller action contains the first use of the secret we defined in our Docker Compose configuration.  We can read secrets passed to our API as files on the container's file system at `/run/secrets/<secret name>`.  Above, we use Ruby's `File.read` method to locate these values and assign them to constants.

Then, using our Github client ID and secret, we instantiate a new instance of the `Github` class provided by the `github_api` gem.  By calling its `get_token` method, we validate the `code` passed through GitHub's redirect and trade it for an API access token.

### Step 9: Retrieving the User's GitHub Profile

With an access token for the user, we can request their public GitHub profile.

``` ruby(/api/app/controllers/api/authentication_controller.rb)
class Api::AuthenticationController < ApplicationController
  GITHUB_CLIENT_SECRET = File.read("/run/secrets/github_client_secret")
  def github
    code = params[:code]
    github = Github.new client_id: ENV["GITHUB_CLIENT_ID"], client_secret: GITHUB_CLIENT_SECRET
    token = github.get_token(code).token
    
+     github_users = Github::Client::Users.new oauth_token: token
+     user = github_users.get
  end
end
```

This simple query, `github_users.get` includes all of the information we need to create or fetch an internal record for the authenticated user.  Before we can move forward though, we need a User model.

### Step 10: Create or Fetch the Internal User

Let's generate a model to store our user records.  For a starting point, I am going to store; GitHub's user ID, the user's profile email address, their username, and avatar URL.

Run the following command to generate your Model; `docker-compose exec api bin/rails generate model user github_id:integer github_email:string username:string avatar:string`

Next, open your generated model and create a method to fetch, or create a new record.

``` ruby(/api/app/models/user.rb)
- # == Schema Information
- #
- # Table name: users
- #
- #  id           :integer          not null, primary key
- #  github_id    :integer
- #  github_email :string
- #  username     :string
- #  avatar       :string
- #  created_at   :datetime         not null
- #  updated_at   :datetime         not null
- #

class User < ApplicationRecord
  def self.create_or_fetch(user)
    find_by(github_id: user.id) || create(
      github_id: user.id,
      github_email: user.email,
      username: user.login,
      avatar: user.avatar_url
    )
  end
end
```

Our `create_or_fetch` method lives up to its name, either using the GitHub ID to fetch an existing record, or creating a new record.

All we need to do is update our controller to utilize this method.

``` ruby(/api/app/controllers/api/authentication_controller.rb)
class Api::AuthenticationController < ApplicationController
  GITHUB_CLIENT_SECRET = File.read("/run/secrets/github_client_secret")
  def github
    code = params[:code]
    github = Github.new client_id: ENV["GITHUB_CLIENT_ID"], client_secret: GITHUB_CLIENT_SECRET
    token = github.get_token(code).token
    
    github_users = Github::Client::Users.new oauth_token: token
+     user = User.create_or_fetch(github_users.get)
  end
end
```

### Step 10: Generate an Internal Token for the User

With the user's identity proven and mapped to our internal records, we no longer need GitHub's authentication token.  We can now transition to an internal token to authenticate ongoing requests from the user against our API.

We are using JSON Web Tokens (JWT), for these internal tokens.  However, to get started, we again need to install a gem.  Use `bundle add` again to install the dependencies for JWT.

Run the following command; `docker-compose exec api bundle add jwt --version 2.1`

Like Github's OAuth tokens, encoding and decoding a JWT relies on secret-key encryption.  We must treat our JWT secret with the same care given Github's.  We created a secret at the beginning of this chapter to store this value in `/.docker/.secrets/jwt_secret.txt`.  Populate this file with a value if you haven't already; you can generate a random string to serve as your secret key.  Just be sure to save it somewhere secure.

We might need to encode and decode tokens from several areas of our application, so we can externalize this process into a module to keep our code DRY.

Create a new module in `controllers/concerns`.

``` ruby(/api/app/controllers/concerns/token_ops.rb)
module TokenOps extend ActiveSupport::Concern
  JWT_SECRET = File.read("/run/secrets/jwt_secret")
  def self.encode(user)
    payload = {
      iss: ENV['CLIENT_URL'],
      id: user.id,
      exp: 30.days.from_now.to_i,
      iat: Time.now.to_i
    }
    JWT.encode payload, JWT_SECRET, 'HS256'
  end

  def self.decode(token)
    options = {
      iss: ENV['CLIENT_URL'],
      verify_iss: true,
      verify_iat: true,
      leeway: 30,
      algorithm: 'HS256'
    }
    JWT.decode token, JWT_SECRET, true, options
  end
end
```

We are only encoding the user's **internal** user ID into this token; it exists solely to validate which user is sending requests to our API.  We won't use this token for any communication with Github.  

This token is also not intended to send user information to our client. For security reasons, we should never send our JWT secret to our client-side application.  That means our client is left unable to decode this token.  If our client needs to receive user data, such as a profile, it must send this token to our API for decoding. The token allows our API to validate which user is making requests.  Then, after proving the requesting user has access, our client receives any data it requires, unencrypted,  as the payload of a request.

### Step 11: Providing the Token to Our Client

Let's upgrade our controller again to build out our token with the new TokenOps module.

``` ruby(/api/app/controllers/api/authentication_controller.rb)
class Api::AuthenticationController < ApplicationController
+   include TokenOps
  GITHUB_CLIENT_SECRET = File.read("/run/secrets/github_client_secret")

  def github
    code = params[:code]
    github = Github.new client_id: ENV["GITHUB_CLIENT_ID"], client_secret: GITHUB_CLIENT_SECRET
    token = github.get_token(code).token
    
    github_users = Github::Client::Users.new oauth_token: token
    user = User.create_or_fetch(github_users.get)
+     jwt = TokenOps.encode(user)
    
+     redirect_to "#{ENV["CLIENT_URL"]}/auth/#{jwt}"
  end
end
```

Our `TokenOps` module is included in this controller to provide our token's encode and decode functions.  To create a JWT token, we pass a User record to `encode`.  Afterward, our API redirects to our client on a new, and currently undefined, `/auth/:token` client route.

We can define this route as a gateway to bring our JWT into our client environment and greenlight a saga to complete authentication client-side.

### Step 12: Completeing the client-side authentication

We still need to translate our JWT token into the user information required to personalize our UI.  To kick off that process, we need a new client-side route.  You can begin by defining some constants.

``` javascript(/client/src/constants/settings.js)
export const HOME_ROUTE = "HOME_ROUTE";
export const CHAPTER_ROUTE = "CHAPTER_ROUTE";
export const AUTH_ROUTE = "AUTH_ROUTE";
```

Next, define this route in our store's `routeMap`.

``` javascript(/client/src/reducers/store.js)
import { createStore, combineReducers, applyMiddleware } from "redux";
import { composeWithDevTools } from 'redux-devtools-extension';
import createSagaMiddleware from 'redux-saga'
import { connectRoutes } from 'redux-first-router';
import restoreScroll from 'redux-first-router-restore-scroll'
import createHistory from 'history/createBrowserHistory';

import * as ROUTES from '../constants/settings';
import chapters from './chapters';
import nodes from './nodes';
import settings from './settings';
import alerts from './alerts';
import rootSaga from '../sagas/root';

const history = createHistory();
const routeMap = {
  // Routes here "ACTION_NAME":"/some/route"
  [ROUTES.HOME_ROUTE]: "/",
  [ROUTES.CHAPTER_ROUTE]: "/chapter/:chapter_id",
+   [ROUTES.AUTH_ROUTE]: "/auth/:token"
};

const { reducer: routeReducer, middleware: routerMiddleware, enhancer: routerEnhancer, initialDispatch } = connectRoutes(
  history,
  routeMap,
  { restoreScroll: restoreScroll(), initialDispatch: false }
);

const reducers = combineReducers({location: routeReducer, settings, nodes, chapters, alerts});

const sagaMiddleware = createSagaMiddleware();

const middlewares = applyMiddleware(sagaMiddleware, routerMiddleware);

const store = createStore(
  reducers, composeWithDevTools(routerEnhancer, middlewares)
);

sagaMiddleware.run(rootSaga);
initialDispatch();

export default store;
```

Finally, define a new saga to administer our authentication process.  After you define this saga, **do not forget to add its watcher to your root saga!**

``` javascript(/client/src/sagas/hydrate_user.js)
import { takeLatest, put, call } from 'redux-saga/effects';
import axios from 'axios';

import * as routes from '../constants/settings';
import { routeHome } from '../actions/routes';

+ export function* hydrateUser(action){
  yield put(routeHome());
  
  try{
+     let user = yield call(axios.get, "/api/hydrate_user?token=" + action.payload.token);
    console.log(user.data);
  } catch(e){
    // We need some error handling
  }
} 

export function* watchAuthRoutes(){
  yield takeLatest(routes.AUTH_ROUTE, hydrateUser);
};
```

`hydateUser` fires in response to our client's `/auth/:token` route.  For the first time, our triggering action also carries data into the saga: the user token in our route action's payload.

Remember, we only decoding our JWT token server-side.  To get unencrypted user data, we need to call our API.  That means we need to switch back to Rails yet again and define the user data endpoint used in this saga, `/api/hydrate_user`.

### Wrapping Up our Simple Authentication

I want to pause here to point out we have fulfilled our spec.  While we haven't done anything with it, our application has established proof of our user's identity.  Our initial design was kept intentionally simple in the hope of making the basics more manageable. However, with those basics covered, there are some topics we should revisit in more detail.

## Token Lifespan and Visibility

We are relying on URL parameters to pass tokens between our API and client.  That URL data persists in our logs, the browser history, and who knows where else.  That's not an ideal treatment for a token granting 30-days of unquestioned access to our application.

I plan to upgrade our URL delivered tokens to use a shortened two-minute lifespan.  We can issue a long-living token during our user hydration, limiting its use to our request headers, making it is less visible than its short-lived counterpart. 

Upgrade `TokenOps to accommodate this plan.

``` ruby(/api/app/controllers/concerns/token_ops.rb)

module TokenOps extend ActiveSupport::Concern
  JWT_SECRET = File.read("/run/secrets/jwt_secret")

+   def self.encode_short(user)
+     short_payload = token_payload(2.minutes.from_now.to_i, user)
+     JWT.encode short_payload, JWT_SECRET, 'HS256'
+   end
  
+   def self.encode_long(user)
+     long_payload = token_payload(30.days.from_now.to_i, user)
+     JWT.encode long_payload, JWT_SECRET, 'HS256'
+   end

  def self.decode(token)
    options = {
      iss: ENV['CLIENT_URL'],
      verify_iss: true,
      verify_iat: true,
      leeway: 30,
      algorithm: 'HS256'
    }
    JWT.decode token, JWT_SECRET, true, options
  end

+   private
+     def self.token_payload(expires, user)
+       {
+         iss: ENV['CLIENT_URL'],
+         id: user.id,
+         exp: expires,
+         iat: Time.now.to_i
+       }
+     end
end
```

Now we can select which token type is issued by our controller according to our needs.  Upgrade `AuthenticationController` to issue the new short-lived token.

``` ruby(/api/app/controllers/api/authentication_controller.rb)
class Api::AuthenticationController < ApplicationController
  include TokenOps
  GITHUB_CLIENT_SECRET = File.read("/run/secrets/github_client_secret")

  def github
    code = params[:code]
    github = Github.new client_id: ENV["GITHUB_CLIENT_ID"], client_secret: GITHUB_CLIENT_SECRET
    token = github.get_token(code).token
    
    github_users = Github::Client::Users.new oauth_token: token
    user = User.create_or_fetch(github_users.get)
+     jwt = TokenOps.encode_short(user)
    
    redirect_to "#{ENV["CLIENT_URL"]}/auth/#{jwt}"
  end
end
```

## Hydrating the Client-Side User

We're almost ready to send our client-side store user data.  Let's create a `User.fsa` scope to limit data passed to our client.

``` ruby(/api/app/models/user.rb)
- # == Schema Information
- #
- # Table name: users
- #
- #  id           :integer          not null, primary key
- #  github_id    :integer
- #  github_email :string
- #  username     :string
- #  avatar       :string
- #  created_at   :datetime         not null
- #  updated_at   :datetime         not null
- #

class User < ApplicationRecord
+   def fsa(token)
+     {
+       id: id,
+       github_email: github_email,
+       username: username,
+       avatar: avatar,
+       token: token
+     }
+   end
  
  def self.create_or_fetch(user)
    find_by(github_id: user.id) || create(
      github_id: user.id,
      github_email: user.email,
      username: user.login,
      avatar: user.avatar_url
    )
  end
end
```

Our "scope" here is actually an instance method on our User model.  We want to issue a long-term token while hydrating our user.  Since that `token` isn't part of our model, our scope method must accept this external data as a parameter when creating its payload.

Next, create a route for a new hydrate_user action.

``` ruby(/api/config/routes.rb)
Rails.application.routes.draw do
  namespace :api do
    get 'github/', to: "authentication#github", format: false
+     get 'hydrate_user/', to: "authentication#show"
    get 'nodes/', to: "nodes#index"
    get 'chapters/', to: "chapters#index"
  end
end
```

Now we can build the matching controller action.

``` ruby(/api/app/controllers/api/authentication_controller.rb)
class Api::AuthenticationController < ApplicationController
  include TokenOps
  GITHUB_CLIENT_SECRET = File.read("/run/secrets/github_client_secret")

  def github
    code = params[:code]
    github = Github.new client_id: ENV["GITHUB_CLIENT_ID"], client_secret: GITHUB_CLIENT_SECRET
    token = github.get_token(code).token
    
    github_users = Github::Client::Users.new oauth_token: token
    user = User.create_or_fetch(github_users.get)
    jwt = TokenOps.encode_short(user)
    
    redirect_to "#{ENV["CLIENT_URL"]}/auth/#{jwt}"
  end

+   def show
+     token = params[:token]
+     user_id = TokenOps.decode(token)[0]["id"]
+     user = User.find(user_id)
+     long_token = TokenOps.encode_long(user)
+     
+     render json: user.fsa(long_token), status: 200
+   end
end
```

Our show action takes a short-term token and uses it to verify the record we need to access.  Decoding the token grants us a user ID which we use to locate our database record.  Then, we encode that returned user again, this time creating a long-term token with a 30-day duration.  

This controller action is the only place we use our short-lived token for authentication, or transmit a token in a URL parameter.  After trading for a 30-day token, we limit its use to our request headers.

We can finish our `userHydration` saga after we prepare our store to manage this state.  Create the following files, and **update your root reducer (not shown).**.

``` javascript(/client/src/constants/user.js)
export const SET_USER = "SET_USER";
export const CLEAR_USER = "CLEAR_USER";
```

``` javascript(/client/src/actions/user.js)
import * as constants from "../constants/user";

export const setUser = (payload) => ({
  type: constants.SET_USER, payload
});

export const clearUser = () => ({ type: constants.CLEAR_USER }) ;
```

``` javascript(/client/src/actions/user.spec.js)
/* global expect */
import * as actions from './user';

let test_user = {
  avatar: "https://avatars0.githubusercontent.com/u/shiba",
  github_email: "awesome@wow.com",
  id: 9000,
  token: "wow.much.secret",
  username: "doge"
};

describe("User actionCreators", ()=>{
  test("setUser() assigns active user", () =>{
    expect(actions.setUser(test_user)).toMatchSnapshot();
  });

  test("clearUser wipes user", () =>{
    expect(actions.clearUser()).toMatchSnapshot();
  });
});
```

``` javascript(/client/src/reducers/user.js)
import * as constants from '../constants/user';
const default_state = {};

const userReducer = function(state = default_state,action){
  switch (action.type) {
    case(constants.SET_USER):
      return {...action.payload};
    case(constants.CLEAR_USER):
      return {};
    default:
      return state;
  }
};

export default userReducer;
```

``` javascript(/client/src/reducers/user.spec.js)
/* global expect */
import  userReducer from './user';
import * as actions from '../actions/user';

let defaultState = {};
let exampleState = {
  avatar: "https://avatars0.githubusercontent.com/u/shiba",
  github_email: "awesome@wow.com",
  id: 9000,
  token: "wow.much.secret",
  username: "doge"
};

describe("User reducer", ()=>{
  test("SET_USER populates user object",()=>{
    let fsa = actions.setUser(exampleState);
    expect(userReducer(defaultState,fsa)).toEqual(exampleState);
  });
  
  test("CLEAR_USER empties user object", () =>{
    expect(userReducer(exampleState, actions.clearUser())).toEqual(defaultState);
  });
});
```

### Resolving User Hydration

Let's finish out the green path of our `hydrateUser` saga.  We need two actions dispatched on successful hydration; one populating user data into our store, and another action alerting users their login succeeded.

``` javascript(/client/src/sagas/hydrate_user.js)
+ import { takeLatest, put, call, all } from 'redux-saga/effects';
import axios from 'axios';

import * as routes from '../constants/settings';
import { routeHome } from '../actions/routes';
import { setUser } from '../actions/user';
import { addAlert } from '../actions/alerts';

export function* hydrateUser(action){
  yield put(routeHome());
  
  try{
    let user = yield call(axios.get, "/api/hydrate_user?token=" + action.payload.token);
+     yield all([
+       put(setUser(user.data)),
+       put(addAlert("Sign in successful, welcome " + user.data.username + ".","success"))
+     ]);
  } catch(e){
    // We need some error handling
  }
} 

export function* watchAuthRoutes(){
  yield takeLatest(routes.AUTH_ROUTE, hydrateUser);
};
```

## Updating Our Authenticated UI

In addition to alerting, our UI should signal our user's authentication completed successfully.  Using the user's avatar URL, we can personalize the GitHub badge seen pre-sign-in with a custom badge.  We are also adding a small dropdown to contain a sign-off link.

Since the profile badge needs a connection to our store, let's refactor it as a standalone component.  Create the new file below.

``` javascript(/client/src/components/user_badge.js)
import React, { Component } from 'react';
import { Image, Menu, Icon, Dropdown } from 'semantic-ui-react';

class UserBadge extends Component {
  render() {
    if(!this.props.username){
      return (
        <Menu.Item href="https://github.com/login/oauth/authorize?client_id=a86bc65853ae65d3be52" name='Sign in with GitHub'>
          <Icon name='github' style={{marginRight: 0}} size="big" />
        </Menu.Item>
      );
    } else {
      let badge = <Image src={this.props.avatar} avatar />;
      return (
        <Menu.Item name={this.props.username}>
          <Dropdown icon={badge} compact pointing="top right">
            <Dropdown.Menu>
+               <Dropdown.Item onClick={this.props.dispatchClearUser}>Sign Out</Dropdown.Item>
            </Dropdown.Menu>
          </Dropdown>
        </Menu.Item>
      );
    }
  }
}

export default UserBadge;
```

A defined username in our store now determines if we render the GitHub badge or a custom avatar.  This component also contains a sign-out link for an authenticated user.

We need to map the props our component needs.  Echoing the design of `ChapterProvider`, let's build a high order component connecting to our user state.

``` javascript(/client/src/containers/user_provider.js)
import { connect } from 'react-redux';

import UserBadge from '../components/user_badge';
import { clearUser } from '../actions/user';

export const connectToUser = (WrappedComponent) => {
   return connect(mapStateToProps,mapDispatchToProps)(WrappedComponent);
};

const mapStateToProps = (state) => ({
  username: state.user.username,
  avatar: state.user.avatar
});

const mapDispatchToProps = (dispatch) => ({
+   dispatchClearUser: (e) => dispatch(clearUser())
});

// EXPORTABLE CONNECTED COMPONENTS
+ export const ConnectedUserBadge = connectToUser(UserBadge);
```

Along with our user state, we are providing a `dispatchClearUser` action which manages user sign-out.  We don't need a server-side sign-out action; nuking tokens client-side makes users unable to complete future authenticated API requests.

Update `MenuBar` to use this upgraded component.

``` javascript(/client/src/components/menu_bar.js)
import React, { Component } from 'react';
import { Container, Image, Menu, Icon } from 'semantic-ui-react';
  
import rrLogo from '../assets/images/reactivating-rails.png';
import { ConnectedChapterMenuItems } from '../containers/chapter_provider';
+ import { ConnectedUserBadge } from '../containers/user_provider';

- const fixedMenuStyle = {
-   backgroundColor: '#fff',
-   border: '1px solid #ddd',
-   boxShadow: '0px 3px 5px rgba(0, 0, 0, 0.2)',
-   paddingTop: "8px",
-   paddingBottom: "8px"
- };

class MenuBar extends Component {
  render() {
    return (
        <Menu borderless stackable fixed="top" style={ fixedMenuStyle }>
          <Container>
            <Menu.Item><Image width='200' src={rrLogo} /></Menu.Item>

            <Menu.Menu position='right'>
              <ConnectedChapterMenuItems />
+               <ConnectedUserBadge />
            </Menu.Menu>
          </Container>
        </Menu>
    );
  }
}

export default MenuBar;
```

There are still some worts on this design.  For one thing, since sign-in and sign-out aren't route changes, alert messages don't clear until the next page view.  We should address this before moving on.  Since we have a `hydrateUser` saga managing sign in, I am naming our signout saga `dehydrateUser`.

``` javascript(/client/src/sagas/dehydrate_user.js)
import { takeLatest, put, all, call } from 'redux-saga/effects';
import { delay } from 'redux-saga';

import * as actions from '../constants/user';
import { addAlert, clearAlerts } from '../actions/alerts';

export function* dehydrateUser(action){
  try{
    yield all([
      put(clearAlerts()),
      put(addAlert("Sign out successful","danger"))
    ]);
    
+     yield call(delay,3000);
+     yield put(clearAlerts());
  } catch(e){
    // We need some error handling
  }
} 

export function* watchSignOut(){
  yield takeLatest(actions.CLEAR_USER, dehydrateUser);
};
```

This saga introduces a utility function for Redux Saga, `delay` which as the name suggests, causes a delay.  We use this above to hold our signout message onscreen for 3 seconds before clearing the alert.  Go ahead and add similar code to `hydrateUser`, so those alerts don't linger either.

``` javascript(/client/src/sagas/hydrate_user.js)
import { takeLatest, put, call, all } from 'redux-saga/effects';
+ import { delay } from 'redux-saga';
import axios from 'axios';

import * as routes from '../constants/settings';
import { routeHome } from '../actions/routes';
import { setUser } from '../actions/user';
+ import { addAlert, clearAlerts } from '../actions/alerts';

export function* hydrateUser(action){
  yield put(routeHome());
  
  try{
    let user = yield call(axios.get, "/api/hydrate_user?token=" + action.payload.token);
    yield all([
      put(setUser(user.data)),
      put(addAlert("Sign in successful, welcome " + user.data.username + ".","success"))
    ]);
    
+     yield call(delay,3000);
+     yield put(clearAlerts());
  } catch(e){
    // We need some error handling
  }
} 

export function* watchAuthRoutes(){
  yield takeLatest(routes.AUTH_ROUTE, hydrateUser);
};
```

This change, at last, brings us to the end of our authentication setup.

Given the length of this chapter, we won't look at our first authenticated requests until chapter 12.  For the moment, we should fill gaps in our test suite before we wrap up.

## Authentication Tests

We should add test coverage for our two new sagas; `hydateUser` and `dehydrateUser`.  Again, since I am not introducing new testing strategies in these specs, we won't cover them in detail.

``` javascript(/client/src/sagas/hydrate_user.spec.js)
/* global expect */
import { call, put } from 'redux-saga/effects';
import { delay } from 'redux-saga';
import axios from 'axios';

import { hydrateUser } from './hydrate_user';
import { routeHome } from '../actions/routes';
import { setUser } from '../actions/user';
import { clearAlerts } from '../actions/alerts';

describe("hydrateUser", () => {
  let action = { type: 'AUTH_ROUTE', payload: { token: "shortTermToken" }};
  let sample_user = {data: {username: "SomeDude"}};
  let saga = hydrateUser(action);

  test("begins by redirecting HOME",() => {
    expect(saga.next().value).toEqual(put(routeHome()));
  });
  
  test("saga then trades temp token for long-term",() => {
    expect(saga.next().value).toEqual(call(axios.get, "/api/hydrate_user?token=" + action.payload.token));
  });
  
  test("saga then sets user state and alerts user", ()=> {
    let results = saga.next(sample_user).value["ALL"];
    expect(results[0]).toEqual(put(setUser(sample_user.data)));
    expect(results[1]["PUT"].action.type).toEqual("ADD_ALERT");
  });
  
  test("saga then delays and clears alerts after timer", ()=> {
    expect(saga.next().value["CALL"]["fn"]).toEqual(delay);
    expect(saga.next().value).toEqual(put(clearAlerts()));
  });
});
```

``` javascript(/client/src/sagas/dehydrate_user.spec.js)
/* global expect */
import { put } from 'redux-saga/effects';
import { delay } from 'redux-saga';

import { dehydrateUser } from './dehydrate_user';
import { clearAlerts } from '../actions/alerts';

describe("dehydrateUser", () => {
  let saga = dehydrateUser();

  test("saga by clearing old alerts and notifying of logout", ()=> {
    let results = saga.next().value["ALL"];
    expect(results[0]).toEqual(put(clearAlerts()));
    expect(results[1]["PUT"].action.type).toEqual("ADD_ALERT");
  });
  
  test("saga then delays and clears alerts after timer", ()=> {
    expect(saga.next().value["CALL"]["fn"]).toEqual(delay);
    expect(saga.next().value).toEqual(put(clearAlerts()));
  });
});
```

### Server-Side Tests

A large piece of our server-side authentication remains undeveloped; we're missing error handling to gracefully manage fraudulent tokens, expired credentials, and other critical failures.  We address these gaps in a future iteration, for now, test only the green path of our authentication system.

To start, let's look at our `TokenOps` class.  We're going to limit testing to ensuring we can encode and decode tokens without losing the critical user ID stored inside.  Create a new directory, `spec/controllers/concerns`, with the following file placed inside.

``` ruby(/api/spec/controllers/concerns/token_ops.spec.rb)
require 'rails_helper'

RSpec.describe TokenOps do
  describe "encode" do
    it "provides an encode short and long  function" do
      expect(TokenOps.respond_to? :encode_short).to be true
      expect(TokenOps.respond_to? :encode_long).to be true
    end
    
    it "can decode a user's id" do
      user = User.create({
        github_id: "test",
        github_email: "test@test.com",
        username:"something_witty",
        avatar:"someimage.gif",
      })
      
      token = TokenOps.encode_short user
      decoded_id = TokenOps.decode(token)[0]["id"]
      expect(decoded_id).to eq user.id
    end
  end
end
```

`User` is the first model complex enough to leave me wanting some test coverage.  Let's ensure our `fsa` "scope" provides the data we need, and that `create_or_fetch` produces the correct outcome whether it needs to locate or build a user.

``` ruby(/api/spec/models/user_spec.rb)
require 'rails_helper'

RSpec.describe User, type: :model do
  before(:each) do
    @user = User.create({
        github_id: 2,
        github_email: "test@test.com",
        username:"something_witty",
        avatar:"someimage.gif",
      })
  end
  
  it "provides .fsa(token) to produce user FSA response object" do
   fsa = @user.fsa("sometoken")
   expect(fsa[:username]).to eq @user.username
   expect(fsa[:token]).to eq "sometoken"
  end
  
  describe "create_or_fetch" do
    it "creates a new user if one cannot be found" do
      User.create_or_fetch(OpenStruct.new({
        id: 1,
        email: "someone",
        username: "someoneelse",
        avatar: "someimage"
      }))
      
      expect(User.all.count).to eq 2
    end
    
    it "returns a recond by github_id if available" do
      requested_user = User.create_or_fetch(OpenStruct.new({id: 2}))
      expect(requested_user).to eq @user
      expect(User.all.count).to eq(1)
    end
  end
end
```

In `AuthenticationController`, test the routes managing the code & token exchange with Github used to authenticate users.

``` ruby(/api/spec/controllers/api/authentication_controller_spec.rb)
require 'rails_helper'

RSpec.describe Api::AuthenticationController, type: :controller do
  describe "GET #github" do
    let(:sample_response) { OpenStruct.new({id: 1, email: "", login: "", avatar_url: ""}) }
   
    before(:each) do
      #create a stub for main Github API class.  Stub is then allowed to respond to 
      # .get_token(code).token chain of our controller with a fake token.
      github = double("github")
      class_double("Github", :new => github).as_stubbed_const(:transfer_nested_constants => true)
      allow(github).to receive_message_chain(:get_token, :token) { "fake token" }
      
      #Similar to above we mock the Client::Users class then allow the returned double
      #github_users to respond to #get with a mocked user profile response.
      @github_users = double("@github_users")
      allow(Github::Client::Users).to receive(:new) { @github_users }
      allow(@github_users).to receive(:get) { sample_response }
    end
    
    it "redirects new users to client" do
      get :github
      expect(response).to have_http_status(302)
    end
    
    it "redirects existing users to client" do
      User.create(github_id: 1, github_email: "someone", username: "someoneelse", avatar: "someimage")
      get :github
      expect(response).to have_http_status(302)
    end
  end
  
  describe "GET #show" do
    it "returns a user profile" do
      user = User.create(github_id: 1, github_email: "someone", username: "someoneelse", avatar: "someimage")
      token = TokenOps.encode_short(user)
      
      get :show, params: {:token => token}
      expect(response).to have_http_status(:success)
      expect(JSON.parse(response.body)).to include("id","username","github_email","token","avatar")
    end
  end
end 
```

Our authentication controller relies heavily on the `github` gem.  We don't want our tests to be firing off actual API requests, so we need to mock some content.  

We begin by creating a `class_double` for the `Github` class.  Using the `.as_stubbed_const(:transfer_nested_constants => true)` option ensures our double replaces the preloaded class and also supplies all the nested modules we need as well.  This option saves us from needing to mock the `Github::Client` and `Github::Clients::Users` modules manually.

Our mocked Github class returns a double when we invoke its `new` method.  `allow` lets us define a mock response when the double's `.get_token(code).token` method chain fires.  That setup ensures we receive a stubbed token needed for next step in our controller, even though we aren't supplying a legitimate API code in exchange.

Our token exchange proceeds much the same, `Github::Client::Users` is allowed to send back its own double `github_users`.  This double responds to a `get` method and returns a mocked user profile.

All of this happens in a before(:each) block for our tests.  Once the prep is behind us, our actual tests are rather simple.  If we return an existing user from GitHub's API, we fetch them from our database.  Otherwise, we check for the creation of a new record.

Our last spec is for the `show` action, where we exchange short and long duration tokens.  Here we create a new user, build a token, and test the response is a code 200.

## Wrapping Up

We now have an early authentication system in place.  We have some limitations, but we completed an OAuth handshake with GitHub.  We also built an internal token system to manage our internal user identity. 

Next chapter we take a step further and write our first authenticated requests; adding new functionality tracking the user's last-read and furthest-read chapter in our book.  That allows us to restore the reader's position on return visits and lays the groundwork for more ambitious features coming in future iterations.